<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alignment on Robert Raynor</title>
    <link>http://rayncloud.com/categories/alignment/</link>
    <description>Recent content in Alignment on Robert Raynor</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 04 Oct 2025 16:04:38 -0700</lastBuildDate>
    <atom:link href="http://rayncloud.com/categories/alignment/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Digital Abstraction, Coordination, and Verifiable AI</title>
      <link>http://rayncloud.com/notes/digital-abstraction-and-coordination/</link>
      <pubDate>Sat, 04 Oct 2025 15:59:37 -0700</pubDate>
      <guid>http://rayncloud.com/notes/digital-abstraction-and-coordination/</guid>
      <description>Thesis: Digital abstraction simplifies coordination by dramatically reducing the complexity of verifiability and enforcement. It is primarily the progress of computation, not game theory, that fuels modern progress in coordination. Since AI happens to be digitally abstracted, it will enable a further revolution in coordination technology.&#xA;Suppose we want to cooperate in order to avoid some kind of prisoners&amp;rsquo;-dilemma-esque tragedy of the commons. A normal pattern here is to agree to cooperate optimistically, and also punish anyone who doesn&amp;rsquo;t cooperate.</description>
    </item>
    <item>
      <title>How intelligence helps (and hurts) alignment</title>
      <link>http://rayncloud.com/notes/intelligence-and-alignment/</link>
      <pubDate>Sun, 05 Mar 2023 21:24:23 -0800</pubDate>
      <guid>http://rayncloud.com/notes/intelligence-and-alignment/</guid>
      <description>&lt;div class=&#34;summary&#34;&gt;&#xA;An initial reaction to AI alignment concerns. &#xA;&lt;/div&gt;</description>
    </item>
  </channel>
</rss>
